{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc918379",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c6f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress = True)\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the Dataset\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8574eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_group = [{'sex': 1}]\n",
    "unpriv_group = [{'sex': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "788a78d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adult = load_preproc_data_adult(['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9092e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_raw_trn, dset_raw_tst = data_adult.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "bdb8a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_trn_pred = dset_raw_trn.copy(deepcopy=True)\n",
    "dset_trn_pred.features = torch.from_numpy(dset_trn_pred.features).float()\n",
    "dset_trn_pred.labels = torch.from_numpy(dset_trn_pred.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b60eeeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference: -0.19334966296595607\n",
      "Disparate Impact: 0.3633812161549577\n",
      "Consistency: 0.7172599374067912\n"
     ]
    }
   ],
   "source": [
    "dset_raw_trn_metrics = BinaryLabelDatasetMetric(dset_raw_trn,\n",
    "                                      unprivileged_groups=unpriv_group,\n",
    "                                     privileged_groups=priv_group)\n",
    "print(\"Statistical Parity Difference:\",dset_raw_trn_metrics.statistical_parity_difference())\n",
    "print(\"Disparate Impact:\",dset_raw_trn_metrics.disparate_impact())\n",
    "print(\"Consistency:\",dset_raw_trn_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "12295ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoding the p features\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(size_in, size_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7dcdd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoding the p features\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(size_in, size_out)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "479d89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decoding back the above encoded features into p features\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(size_in, size_out) # Should be reverse of that of Encoder's\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.linear1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2dc5b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairAutoEnc(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(input_dim, hidden_dim)\n",
    "        self.dec = Decoder(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "3e36bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why the dimension of latent space is 1 less than that of feature space?\n",
    "# We want to kinda disperse the protected variable among other variables\n",
    "fair_autoenc = FairAutoEnc(len(data_adult.feature_names),\n",
    "                           len(data_adult.feature_names)-1,\n",
    "                          len(data_adult.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0392f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(fair_autoenc.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b8cb6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fnr_score_diff(x_recon):\n",
    "#     bool_vec1 = torch.logical_and((x_recon[:, 1] >= 0.5),(torch.ravel(dset_trn_pred.labels) == 1))\n",
    "#     bool_vec2 = torch.logical_and((x_recon[:, 1] < 0.5),(torch.ravel(dset_trn_pred.labels) == 1))\n",
    "#     NA_pos = torch.sum(bool_vec1)\n",
    "#     NB_pos = torch.sum(bool_vec2)\n",
    "#     FNR_A = torch.sum(dset_trn_pred.labels[bool_vec1])\n",
    "#     FNR_B = torch.sum(dset_trn_pred.labels[bool_vec2])\n",
    "#     return torch.abs(-FNR_A/NA_pos + FNR_B/NB_pos)\n",
    "\n",
    "# def fpr_score_diff(x_recon):\n",
    "#     bool_vec1 = torch.logical_and((x_recon[:, 1] >= 0.5),(torch.ravel(dset_trn_pred.labels) == 0))\n",
    "#     bool_vec2 = torch.logical_and((x_recon[:, 1] < 0.5),(torch.ravel(dset_trn_pred.labels) == 0))\n",
    "#     NA_neg = torch.sum(bool_vec1)\n",
    "#     NB_neg = torch.sum(bool_vec2)\n",
    "#     FPR_A = torch.sum(dset_trn_pred.labels[bool_vec1])\n",
    "#     FPR_B = torch.sum(dset_trn_pred.labels[bool_vec2])\n",
    "#     return torch.abs(-FPR_A/NA_neg + FPR_B/NB_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "27ba6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stat_par_diff(x_recon):\n",
    "#     prob_suc_A = torch.sum(torch.logical_and(torch.ravel(dset_trn_pred.labels) == 1, x_recon[:, 1] <= 0.5))\n",
    "#     prob_suc_B = torch.sum(torch.logical_and(torch.ravel(dset_trn_pred.labels) == 1, x_recon[:, 1] > 0.5))\n",
    "#     prob_A = torch.sum(x_recon[:,1] <= 0.5)\n",
    "#     prob_B = torch.sum(x_recon[:,1] > 0.5)\n",
    "#     if prob_A.item() == 0:\n",
    "#         cond_prob_suc_A = prob_A\n",
    "#     else:\n",
    "#         cond_prob_suc_A = prob_suc_A/prob_A\n",
    "#     if prob_B.item() == 0:\n",
    "#         cond_prob_suc_B = prob_B\n",
    "#     else:\n",
    "#         cond_prob_suc_B = prob_suc_B/prob_B\n",
    "#     return torch.abs(cond_prob_suc_A - cond_prob_suc_B)\n",
    "\n",
    "# def disp_imp(x_recon):\n",
    "#     prob_suc_A = torch.sum(torch.logical_and(torch.ravel(dset_trn_pred.labels) == 1, x_recon[:, 1] <= 0.5))\n",
    "#     prob_suc_B = torch.sum(torch.logical_and(torch.ravel(dset_trn_pred.labels), x_recon[:, 1] > 0.5))\n",
    "#     prob_A = torch.sum(x_recon[:,1] <= 0.5)\n",
    "#     prob_B = torch.sum(x_recon[:,1] > 0.5)\n",
    "#     return torch.abs(1 - ((prob_suc_A/prob_A) / (prob_suc_B/prob_B)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "c32c2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_par_diff(x_recon):\n",
    "    prob_suc_A = torch.sum(x_recon[:,1][torch.ravel(dset_trn_pred.labels) == 0])\n",
    "    prob_suc_B = torch.sum(x_recon[:,1][torch.ravel(dset_trn_pred.labels) == 1])\n",
    "    prob_A = torch.sum(x_recon[:,1][x_recon[:,1] <= 0.5])\n",
    "    prob_B = torch.sum(x_recon[:,1][x_recon[:,1] > 0.5])\n",
    "    if prob_A.item() == 0:\n",
    "        cond_prob_suc_A = prob_A\n",
    "    else:\n",
    "        cond_prob_suc_A = prob_suc_A/prob_A\n",
    "    if prob_B.item() == 0:\n",
    "        cond_prob_suc_B = prob_B\n",
    "    else:\n",
    "        cond_prob_suc_B = prob_suc_B/prob_B\n",
    "    return torch.abs(cond_prob_suc_A - cond_prob_suc_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "14add39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_auto(x_old, x_recon, C1=1):\n",
    "    non_prot_cols = [0]+list(range(2,len(dset_trn_pred.feature_names)))\n",
    "    return criterion(x_recon[:,non_prot_cols], x_old[:, non_prot_cols]) + C1*stat_par_diff(x_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "fa2a14da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fair_autoenc:\n",
      "epoch: 200, loss = 0.3552\n",
      "epoch: 400, loss = 0.3423\n",
      "epoch: 600, loss = 0.3391\n",
      "epoch: 800, loss = 0.3374\n",
      "epoch: 1000, loss = 0.3361\n",
      "epoch: 1200, loss = 0.3349\n",
      "epoch: 1400, loss = 0.3337\n",
      "epoch: 1600, loss = 0.3323\n",
      "epoch: 1800, loss = 0.3309\n",
      "epoch: 2000, loss = 0.3294\n",
      "Trained fair_autoenc's Performance on Training Data:\n",
      "Statistical Parity Difference: -0.19334966296595607\n",
      "Disparate Impact: 0.3633812161549577\n"
     ]
    }
   ],
   "source": [
    "# Training fair_autoenc\n",
    "print(\"Training fair_autoenc:\")\n",
    "fair_autoenc.train()\n",
    "for epoch in range(num_epochs):\n",
    "    dset_trn_pred.features = fair_autoenc(torch.from_numpy(dset_raw_trn.features).float())\n",
    "    loss= loss_auto(torch.from_numpy(dset_raw_trn.features).float(), dset_trn_pred.features)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 200== 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "print(\"Trained fair_autoenc's Performance on Training Data:\")        \n",
    "with torch.no_grad():\n",
    "    keep = dset_trn_pred.features\n",
    "    dset_trn_pred.features = (dset_trn_pred.features > 0.55).numpy().astype(float)\n",
    "    dset_trn_pred.labels = dset_trn_pred.labels.numpy()\n",
    "    \n",
    "    x_recon_metrics = BinaryLabelDatasetMetric(dset_trn_pred,\n",
    "                                        unprivileged_groups=unpriv_group,\n",
    "                                        privileged_groups=priv_group)\n",
    "    print(\"Statistical Parity Difference:\",x_recon_metrics.statistical_parity_difference())\n",
    "    print(\"Disparate Impact:\",x_recon_metrics.disparate_impact())\n",
    "    # print(\"Consistency:\",x_recon_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d1ad495c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8487, 0.5074, 0.0569,  ..., 0.0381, 0.0570, 0.3228],\n",
       "        [0.8458, 0.5143, 0.0622,  ..., 0.0431, 0.0617, 0.2778],\n",
       "        [0.8522, 0.5096, 0.0520,  ..., 0.0347, 0.0512, 0.3176],\n",
       "        ...,\n",
       "        [0.8217, 0.5026, 0.0566,  ..., 0.0393, 0.0528, 0.3535],\n",
       "        [0.8290, 0.5058, 0.0596,  ..., 0.0422, 0.0577, 0.2830],\n",
       "        [0.8396, 0.5155, 0.0572,  ..., 0.0410, 0.0558, 0.2651]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "982264f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FairAutoEnc(\n",
       "  (enc): Encoder(\n",
       "    (linear1): Linear(in_features=18, out_features=17, bias=True)\n",
       "    (act1): Sigmoid()\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (linear1): Linear(in_features=17, out_features=18, bias=True)\n",
       "    (act1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_autoenc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "27878d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "fair_dset_trn = fair_autoenc(torch.from_numpy(dset_raw_trn.features).float())\n",
    "dset_trn = scaler.fit_transform(fair_dset_trn.detach().numpy())\n",
    "y_trn = dset_raw_trn.labels.ravel()\n",
    "dset_trn = torch.from_numpy(dset_trn).float()\n",
    "y_trn = torch.from_numpy(y_trn).float()\n",
    "y_trn = y_trn.view(y_trn.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e7b0efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(nn.Module):\n",
    "    def __init__(self, size_in):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(size_in, 1)\n",
    "    def forward(self, x):\n",
    "        prob_pred = torch.sigmoid(self.linear(x))\n",
    "        return prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "485a47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Log_Reg(len(dset_raw_trn.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ba9b918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000 # Number of Epochs\n",
    "learning_rate = 0.01 # Learning Rate\n",
    "\n",
    "# Stochastic Gradient Descent Optimizers\n",
    "optimizer_M = torch.optim.SGD(M.parameters(), lr= learning_rate)\n",
    "\n",
    "# Binary Cross Entropy Loss Functions\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ae618ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_trn_pred = dset_raw_trn.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0da13693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training M:\n",
      "epoch: 200, loss = 0.5496\n",
      "epoch: 400, loss = 0.5042\n",
      "epoch: 600, loss = 0.4821\n",
      "epoch: 800, loss = 0.4699\n",
      "epoch: 1000, loss = 0.4625\n",
      "epoch: 1200, loss = 0.4577\n",
      "epoch: 1400, loss = 0.4543\n",
      "epoch: 1600, loss = 0.4518\n",
      "epoch: 1800, loss = 0.4499\n",
      "epoch: 2000, loss = 0.4483\n",
      "Trained M's Performance on Training Data:\n",
      "Accuracy: 0.802568077451812\n",
      "Predictive Parity Difference: -0.6474059003051882\n",
      "FNR Difference: 0.4577100115074798\n",
      "FPR Difference: -0.10873384364412098\n",
      "Accuracy Difference: -0.13004691067237806\n",
      "Statistical Parity Difference: -0.2147225862822193\n",
      "Disparate Impact: 0.0\n",
      "Consistency: 0.7172599374067912\n"
     ]
    }
   ],
   "source": [
    "# Training M\n",
    "print(\"Training M:\")\n",
    "M.train()\n",
    "for epoch in range(num_epochs):\n",
    "    p_pred = M(dset_trn)\n",
    "    loss= criterion(p_pred, y_trn)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_M.step()\n",
    "    \n",
    "    optimizer_M.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 200== 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "print(\"Trained M's Performance on Training Data:\")        \n",
    "with torch.no_grad():\n",
    "    dset_trn_pred.labels = (p_pred > 0.5).numpy().astype(float)\n",
    "    \n",
    "    mod_metrics = ClassificationMetric(dset_raw_trn, dset_trn_pred,\n",
    "                                        unprivileged_groups=unpriv_group,\n",
    "                                        privileged_groups=priv_group)\n",
    "    print(\"Accuracy:\", mod_metrics.accuracy())\n",
    "    print(\"Predictive Parity Difference:\", mod_metrics.positive_predictive_value(False)-mod_metrics.positive_predictive_value(True))\n",
    "    print(\"FNR Difference:\", mod_metrics.false_negative_rate_difference())\n",
    "    print(\"FPR Difference:\", mod_metrics.false_positive_rate_difference())\n",
    "    print(\"Accuracy Difference:\", mod_metrics.error_rate_difference())\n",
    "    print(\"Statistical Parity Difference:\",mod_metrics.statistical_parity_difference())\n",
    "    print(\"Disparate Impact:\",mod_metrics.disparate_impact())\n",
    "    print(\"Consistency:\",mod_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9592e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_metrics = ClassificationMetric(dset_raw_tst, dset_trn_pred,\n",
    "                                        unprivileged_groups=unpriv_group,\n",
    "                                        privileged_groups=priv_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "14f901e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34189, 1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_trn_pred.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "59615e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14653, 1)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_raw_tst.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "ecd31b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8487, 0.5074, 0.0569,  ..., 0.0381, 0.0570, 0.3229],\n",
       "        [0.8458, 0.5143, 0.0622,  ..., 0.0430, 0.0617, 0.2778],\n",
       "        [0.8522, 0.5096, 0.0520,  ..., 0.0347, 0.0512, 0.3176],\n",
       "        ...,\n",
       "        [0.8217, 0.5026, 0.0566,  ..., 0.0393, 0.0528, 0.3536],\n",
       "        [0.8290, 0.5058, 0.0596,  ..., 0.0422, 0.0577, 0.2830],\n",
       "        [0.8396, 0.5155, 0.0572,  ..., 0.0410, 0.0558, 0.2651]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_dset_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c7c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
