{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92ff054",
   "metadata": {},
   "source": [
    "## FAIRNESS BY REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6bbb5",
   "metadata": {},
   "source": [
    "Here we will see how we can use the popular variance reduction technique in machine learning model to get a fair trained classifier. We will be using the [Adult Dataset](https://archive.ics.uci.edu/ml/datasets/adult) for our demonstration purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0f7ad",
   "metadata": {},
   "source": [
    "### IMPORTNG THE NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0285e3",
   "metadata": {},
   "source": [
    "We will be using the open-source [AIF360](https://github.com/Trusted-AI/AIF360) package to use several fairness based metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ca401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress = True)\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the Dataset\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from common_utils import compute_metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0158b8",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85aa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_group = [{'sex':1}]\n",
    "unpriv_group = [{'sex':0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49036bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adult = load_preproc_data_adult(['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833575e0",
   "metadata": {},
   "source": [
    "### FAIRNESS BASED REGULARIZED CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab218c3",
   "metadata": {},
   "source": [
    "Here we will fit a regularized logistic regression classifier using different regularization terms for each trained model, to compare the results in terms of accuracy and fairness levels achieved by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78545b87",
   "metadata": {},
   "source": [
    "#### - EQUALISED ODDS REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d2a757",
   "metadata": {},
   "source": [
    "- **METHOD**\n",
    "\n",
    "Here we will try to achieve a classifier with equalized odds using a regularization term in the loss function which has difference in the values of FPR and FNR for both the classes as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451c397",
   "metadata": {},
   "source": [
    "$$Loss(\\theta;G,X)\\ =\\ -ll(\\theta;G,X) + C_1|FPR(G=f)-FPR(G=m)|\\\\ + C_2|FNR(G=f)-FNR(G=m)| + \\frac{1}{2}C_3||\\theta||_2^2$$\n",
    "where, \n",
    "$$ll(\\theta;G,X) = \\sum_{i=1}^n y_i\\log(S(x_i^T.\\theta))+(1-y_i)\\log(1-S(x_i^T.\\theta))\\\\ S(x) = \\frac{1}{1+e^{-x}}$$\n",
    "and $\\theta$ represents the weights and biases of the model and $G,X$ is the given data.\n",
    "\n",
    "We want to find the optimal value of $\\theta^*$ such that,\n",
    "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
    "$$\\theta^* = \\argmin_\\theta Loss(\\theta;G,X)$$\n",
    "\n",
    "To solve this above optimization problem, we use gradient descent, starting with an initial value of $\\theta_0$, we update the weights and biases as follows,\n",
    "$$\\theta^{n+1} = \\theta^{n} - lr\\cdot \\frac{\\partial Loss(\\theta;G,X)}{\\partial \\theta}$$\n",
    "where, $lr$ is the learning rate.\n",
    "\n",
    "We will use the common variant of the gradient descent, Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531507c7",
   "metadata": {},
   "source": [
    "To train our model, we will split our data into 2 parts i.e. training data and a test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddefe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_raw_trn, dset_raw_tst = data_adult.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec4952e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_trn_pred = dset_raw_trn.copy(deepcopy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314a322",
   "metadata": {},
   "source": [
    "Taking a look at the fairness metrics for the test data and the proportion of protected group and labels, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28e7a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prop_prtced_grp_lab(data, title=\"\", figsize=(10,8)):\n",
    "    feature_idx = np.where(np.array(data.feature_names) == data.protected_attribute_names[0])[0][0]\n",
    "    n_p_fav = len(np.where(np.logical_and(data.features[:,feature_idx] == data.privileged_protected_attributes[0],data.labels == data.favorable_label) == True)[0])\n",
    "    n_unp_fav = len(np.where(np.logical_and(data.features[:,feature_idx] == data.unprivileged_protected_attributes[0],data.labels == data.favorable_label) == True)[0])\n",
    "    n_p_unfav = len(np.where(np.logical_and(data.features[:,feature_idx] == data.privileged_protected_attributes[0],data.labels == data.unfavorable_label) == True)[0])\n",
    "    n_unp_unfav = len(np.where(np.logical_and(data.features[:,feature_idx] == data.unprivileged_protected_attributes[0],data.labels == data.unfavorable_label) == True)[0])\n",
    "    plt.figure(figsize=figsize)\n",
    "    xlocs = [i for i in range(4)]\n",
    "    y = [n_p_fav/(n_p_fav+n_p_unfav), n_unp_fav/(n_unp_fav+n_unp_unfav), n_p_unfav/(n_p_fav+n_p_unfav), n_unp_unfav/(n_unp_fav+n_unp_unfav)]\n",
    "    plt.bar(['priv grp,fav label','unpriv grp,fav label', 'priv grp,unfav label', 'unpriv grp,unfav label'], y)\n",
    "    for i, v in enumerate(y):\n",
    "        plt.text(xlocs[i] - 0.05, v + 0.01, str(round(v,2)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c584b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference: -0.2011591902342209\n",
      "Disparate Impact: 0.3404494741177242\n",
      "Consistency: 0.7363679792534046\n"
     ]
    }
   ],
   "source": [
    "dset_raw_tst_metrics = BinaryLabelDatasetMetric(dset_raw_tst,\n",
    "                                      unprivileged_groups=unpriv_group,\n",
    "                                     privileged_groups=priv_group)\n",
    "print(\"Statistical Parity Difference:\",dset_raw_tst_metrics.statistical_parity_difference())\n",
    "print(\"Disparate Impact:\",dset_raw_tst_metrics.disparate_impact())\n",
    "print(\"Consistency:\",dset_raw_tst_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c6a85",
   "metadata": {},
   "source": [
    "We see the training data is quite unfair. The statistical parity difference is significantly below 0 implying the data shows disfavor of the unprivileged group to the favorable outcome. Disparate Impact also shows that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab9155",
   "metadata": {},
   "source": [
    "- **FITTING MODELS**\n",
    "    - No Fairness Regularized Classifier (Model: $M$)\n",
    "    - Equalized Odd Regularized Classifier (Model: $M_F$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f34776",
   "metadata": {},
   "source": [
    "Standardizing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f13816ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "dset_trn = scaler.fit_transform(dset_raw_trn.features)\n",
    "y_trn = dset_raw_trn.labels.ravel()\n",
    "dset_trn = torch.from_numpy(dset_trn).float()\n",
    "y_trn = torch.from_numpy(y_trn).float()\n",
    "y_trn = y_trn.view(y_trn.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284eecbb",
   "metadata": {},
   "source": [
    "Logistic Regression Class as needed by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "66a0d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Reg(nn.Module):\n",
    "    def __init__(self, size_in):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(size_in, 1)\n",
    "    def forward(self, x):\n",
    "        prob_pred = torch.sigmoid(self.linear(x))\n",
    "        return prob_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2392f35",
   "metadata": {},
   "source": [
    "Below are the two models $M$ and $M_F$ as mentioned before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "28708317",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Log_Reg(len(dset_raw_trn.feature_names)) # Non-Fairness Based Regularized Model\n",
    "M_F = Log_Reg(len(dset_raw_trn.feature_names)) # Fairness Based Regularization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6841bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000 # Number of Epochs\n",
    "learning_rate = 0.01 # Learning Rate\n",
    "\n",
    "# Stochastic Gradient Descent Optimizers\n",
    "optimizer_M = torch.optim.SGD(M.parameters(), lr= learning_rate)\n",
    "optimizer_M_F = torch.optim.SGD(M_F.parameters(), lr= learning_rate)\n",
    "\n",
    "# Binary Cross Entropy Loss Functions\n",
    "criterion = nn.BCELoss()\n",
    "criterion_f = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ea3ba533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used Values in the FPR and FNR Score Diffs\n",
    "trn_data_metric = BinaryLabelDatasetMetric(dset_raw_trn, \n",
    "                                           unprivileged_groups=unpriv_group,\n",
    "                                          privileged_groups=priv_group)\n",
    "NA_pos = trn_data_metric.num_positives(True)\n",
    "NA_neg = trn_data_metric.num_negatives(True)\n",
    "NB_pos = trn_data_metric.num_positives(False)\n",
    "NB_neg = trn_data_metric.num_negatives(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a873bd",
   "metadata": {},
   "source": [
    "Defining the fairness based regularization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "11aeee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnr_score_diff(p_pred):\n",
    "    FNR_A = torch.sum(p_pred[:,0][np.logical_and((dset_raw_trn.features[:,1] == 1),(dset_raw_trn.labels.ravel() == 1))])\n",
    "    FNR_B = torch.sum(p_pred[:,0][np.logical_and((dset_raw_trn.features[:,1] == 0),(dset_raw_trn.labels.ravel() == 1))])\n",
    "    return torch.abs(-FNR_A/NA_pos + FNR_B/NB_pos)\n",
    "\n",
    "def fpr_score_diff(p_pred):\n",
    "    FPR_A = torch.sum(p_pred[:,0][np.logical_and((dset_raw_trn.features[:,1] == 1),(dset_raw_trn.labels.ravel() == 0))])\n",
    "    FPR_B = torch.sum(p_pred[:,0][np.logical_and((dset_raw_trn.features[:,1] == 0),(dset_raw_trn.labels.ravel() == 0))])\n",
    "    return torch.abs(-FPR_A/NA_neg + FPR_B/NB_neg)\n",
    "\n",
    "# Fairness Based Regularized Loss\n",
    "def loss_f(p_pred, y, C1=1, C2=1):\n",
    "    return criterion_f(p_pred, y_trn) + C1*fpr_score_diff(p_pred) + C2*fnr_score_diff(p_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c206e46",
   "metadata": {},
   "source": [
    "Training the non-fairness regularized Model $M$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ff671cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss = 0.5680\n",
      "epoch: 400, loss = 0.4984\n",
      "epoch: 600, loss = 0.4680\n",
      "epoch: 800, loss = 0.4523\n",
      "epoch: 1000, loss = 0.4433\n",
      "epoch: 1200, loss = 0.4376\n",
      "epoch: 1400, loss = 0.4339\n",
      "epoch: 1600, loss = 0.4314\n",
      "epoch: 1800, loss = 0.4295\n",
      "epoch: 2000, loss = 0.4282\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040012869636433\n",
      "Predictive Parity Difference: -0.6591823766151239\n",
      "FNR Difference: 0.4481566820276498\n",
      "FPR Difference: -0.10084612973989344\n",
      "Accuracy Difference: -0.12600544053524831\n",
      "Statistical Parity Difference: -0.20616620813135944\n",
      "Disparate Impact: 0.0\n",
      "Consistency: 0.7117844920881018\n"
     ]
    }
   ],
   "source": [
    "# Training M\n",
    "for epoch in range(num_epochs):\n",
    "    p_pred = M(dset_trn)\n",
    "    loss= criterion(p_pred, y_trn)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_M.step()\n",
    "    \n",
    "    optimizer_M.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 200== 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    dset_trn_pred.labels = (p_pred > 0.5).numpy().astype(float)\n",
    "    \n",
    "    mod_metrics = ClassificationMetric(dset_raw_trn, dset_trn_pred,\n",
    "                                        unprivileged_groups=unpriv_group,\n",
    "                                        privileged_groups=priv_group)\n",
    "    print(\"Accuracy:\", mod_metrics.accuracy())\n",
    "    print(\"Predictive Parity Difference:\", mod_metrics.positive_predictive_value(False)-mod_metrics.positive_predictive_value(True))\n",
    "    print(\"FNR Difference:\", mod_metrics.false_negative_rate_difference())\n",
    "    print(\"FPR Difference:\", mod_metrics.false_positive_rate_difference())\n",
    "    print(\"Accuracy Difference:\", mod_metrics.error_rate_difference())\n",
    "    print(\"Statistical Parity Difference:\",mod_metrics.statistical_parity_difference())\n",
    "    print(\"Disparate Impact:\",mod_metrics.disparate_impact())\n",
    "    print(\"Consistency:\",mod_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086c204",
   "metadata": {},
   "source": [
    "The above model without any fairness intervention performs very bad in terms of fairness. We have seen this before in the [Adult Dataset Model](Fairness-Definitios-Comparison.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fc1e6",
   "metadata": {},
   "source": [
    "Training Fairness Regularized Model $M_F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b2ac6cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss = 0.5626\n",
      "epoch: 400, loss = 0.5023\n",
      "epoch: 600, loss = 0.4783\n",
      "epoch: 800, loss = 0.4660\n",
      "epoch: 1000, loss = 0.4604\n",
      "epoch: 1200, loss = 0.4586\n",
      "epoch: 1400, loss = 0.4546\n",
      "epoch: 1600, loss = 0.4507\n",
      "epoch: 1800, loss = 0.4494\n",
      "epoch: 2000, loss = 0.4506\n",
      "Accuracy: 0.7874755038170171\n",
      "Predictive Parity Difference: -0.30635049232887146\n",
      "FNR Difference: -0.007485279057859784\n",
      "FPR Difference: 0.0037505784120530905\n",
      "Accuracy Difference: -0.09950058351127222\n",
      "Statistical Parity Difference: -0.05328642112351421\n",
      "Disparate Impact: 0.6953293989245064\n",
      "Consistency: 0.7117844920881018\n"
     ]
    }
   ],
   "source": [
    "# Training M_F\n",
    "for epoch in range(num_epochs):\n",
    "    p_pred = M_F(dset_trn)\n",
    "    \n",
    "    loss= loss_f(p_pred, y_trn)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_M_F.step()\n",
    "    \n",
    "    optimizer_M_F.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 200== 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    dset_trn_pred.labels = (p_pred > 0.5).numpy().astype(float)\n",
    "    plot_prop_prtced_grp_lab(dset_trn_pred, \"Proportion of Groups and Labels of Fairness Intervened Model on Training Data\")\n",
    "    mod_metrics = ClassificationMetric(dset_raw_trn, dset_trn_pred,\n",
    "                                        unprivileged_groups=unpriv_group,\n",
    "                                        privileged_groups=priv_group)\n",
    "    print(\"Accuracy:\", mod_metrics.accuracy())\n",
    "    print(\"Predictive Parity Difference:\", mod_metrics.positive_predictive_value(False)-mod_metrics.positive_predictive_value(True))\n",
    "    print(\"FNR Difference:\", mod_metrics.false_negative_rate_difference())\n",
    "    print(\"FPR Difference:\", mod_metrics.false_positive_rate_difference())\n",
    "    print(\"Accuracy Difference:\", mod_metrics.error_rate_difference())\n",
    "    print(\"Statistical Parity Difference:\",mod_metrics.statistical_parity_difference())\n",
    "    print(\"Disparate Impact:\",mod_metrics.disparate_impact())\n",
    "    print(\"Consistency:\",mod_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074bc2a",
   "metadata": {},
   "source": [
    "We see the fairness regularized model makes the training data much more fairer at a small cost of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9cbf7",
   "metadata": {},
   "source": [
    "From the training set performance we see that the model accuracy decreased by 1.3% but this helped us achieve a fairer classifier with very low FNR and FPR values, Predictive Parity Difference also decreased substantially and accuracy difference became nearer to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1df8d",
   "metadata": {},
   "source": [
    "- **EVALUATING MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64184bc8",
   "metadata": {},
   "source": [
    "Looking at the fairness metric and proportion histogram of the test set, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a775cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prop_prtced_grp_lab(dset_raw_tst, \"Proportion of Groups and Labels on Test Data\")\n",
    "dset_raw_tst_metrics = BinaryLabelDatasetMetric(dset_raw_tst,\n",
    "                                      unprivileged_groups=unpriv_group,\n",
    "                                     privileged_groups=priv_group)\n",
    "print(\"Statistical Parity Difference:\",dset_raw_tst_metrics.statistical_parity_difference())\n",
    "print(\"Disparate Impact:\",dset_raw_tst_metrics.disparate_impact())\n",
    "print(\"Consistency:\",dset_raw_tst_metrics.consistency()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf865e",
   "metadata": {},
   "source": [
    "Looking at the Model $M$'s performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14afdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_tst_pred = dset_raw_tst.copy(deepcopy=True)\n",
    "dset_tst = scaler.transform(dset_tst_pred.features)\n",
    "dset_tst_pred.labels = (M(dset_tst) > 0.5).numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ff6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_metrics = ClassificationMetric(dset_raw_tst, dset_tst_pred,\n",
    "                                    unprivileged_groups=unpriv_group,\n",
    "                                    privileged_groups=priv_group)\n",
    "plot_prop_prtced_grp_lab(dset_raw_tst, \"Proportion of Groups and Labels on Model Predicted Test Data Labels\")\n",
    "print(\"Accuracy:\", mod_metrics.accuracy())\n",
    "print(\"Predictive Parity Difference:\", mod_metrics.positive_predictive_value(False)-mod_metrics.positive_predictive_value(True))\n",
    "print(\"FNR Difference:\", mod_metrics.false_negative_rate_difference())\n",
    "print(\"FPR Difference:\", mod_metrics.false_positive_rate_difference())\n",
    "print(\"Accuracy Difference:\", mod_metrics.error_rate_difference())\n",
    "print(\"Statistical Parity Difference:\",mod_metrics.statistical_parity_difference())\n",
    "print(\"Disparate Impact:\",mod_metrics.disparate_impact())\n",
    "print(\"Consistency:\",mod_metrics.consistency()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
